{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25afe694-edc4-41a1-aaad-94799e10ace6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T08:57:49.017547Z",
     "iopub.status.busy": "2024-09-04T08:57:49.016862Z",
     "iopub.status.idle": "2024-09-04T08:57:49.021843Z",
     "shell.execute_reply": "2024-09-04T08:57:49.020928Z",
     "shell.execute_reply.started": "2024-09-04T08:57:49.017510Z"
    }
   },
   "source": [
    "# FP-Growth\n",
    "\n",
    "频繁项挖掘\n",
    "\n",
    "数据集：[Groceries dataset](https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "547460f0-7fef-46af-a467-6880c958ccd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:22.353347Z",
     "iopub.status.busy": "2024-09-06T14:04:22.353102Z",
     "iopub.status.idle": "2024-09-06T14:04:24.849421Z",
     "shell.execute_reply": "2024-09-06T14:04:24.848469Z",
     "shell.execute_reply.started": "2024-09-06T14:04:22.353324Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150e8730-d2de-431f-b6e9-3531970e243d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:24.851454Z",
     "iopub.status.busy": "2024-09-06T14:04:24.850684Z",
     "iopub.status.idle": "2024-09-06T14:04:24.855907Z",
     "shell.execute_reply": "2024-09-06T14:04:24.855081Z",
     "shell.execute_reply.started": "2024-09-06T14:04:24.851415Z"
    }
   },
   "outputs": [],
   "source": [
    "CSV_PATH = './data'\n",
    "CSV_FILE = 'Groceries_dataset.csv'\n",
    "PLK_FILE = 'item_list.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73cf34-160f-4251-a4ba-f48a7d383515",
   "metadata": {},
   "source": [
    "## 1. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f281e0-21bc-42df-be78-7709535e7cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:24.857654Z",
     "iopub.status.busy": "2024-09-06T14:04:24.857121Z",
     "iopub.status.idle": "2024-09-06T14:04:35.219419Z",
     "shell.execute_reply": "2024-09-06T14:04:35.218652Z",
     "shell.execute_reply.started": "2024-09-06T14:04:24.857620Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/06 22:04:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------+\n",
      "|Member_number|      Date| itemDescription|\n",
      "+-------------+----------+----------------+\n",
      "|         1808|21-07-2015|  tropical fruit|\n",
      "|         2552|05-01-2015|      whole milk|\n",
      "|         2300|19-09-2015|       pip fruit|\n",
      "|         1187|12-12-2015|other vegetables|\n",
      "|         3037|01-02-2015|      whole milk|\n",
      "|         4941|14-02-2015|      rolls/buns|\n",
      "|         4501|08-05-2015|other vegetables|\n",
      "|         3803|23-12-2015|      pot plants|\n",
      "|         2762|20-03-2015|      whole milk|\n",
      "|         4119|12-02-2015|  tropical fruit|\n",
      "+-------------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 创建 SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"App\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 将日志级别设为 WARN\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "# 从 CSV 中读取数据，存成 Pandas DataFrame\n",
    "abs_path = utils.gen_abspath(CSV_PATH, CSV_FILE)\n",
    "df = utils.read_csv(abs_path)\n",
    "\n",
    "# 将 Pandas DataFrame 加载到 Spark\n",
    "spark_df = spark.createDataFrame(df)\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39006c-1c50-4e0a-99ea-21f15c681cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-04T09:29:09.362928Z",
     "iopub.status.busy": "2024-09-04T09:29:09.362505Z",
     "iopub.status.idle": "2024-09-04T09:29:09.373161Z",
     "shell.execute_reply": "2024-09-04T09:29:09.371965Z",
     "shell.execute_reply.started": "2024-09-04T09:29:09.362895Z"
    }
   },
   "source": [
    "设计一个转换类 `Convert`，将 `itemDescription` 的字段值编码成整数，这样做的好处是可以节省内存。\n",
    "\n",
    "`Convert` 提供两个方法：\n",
    "- 一个方法将字段值映射成整数\n",
    "- 另一个方法将整数映射回字段值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d018d452-2aae-475b-8d0d-02b7f8d4cf31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:35.221395Z",
     "iopub.status.busy": "2024-09-06T14:04:35.220931Z",
     "iopub.status.idle": "2024-09-06T14:04:35.228892Z",
     "shell.execute_reply": "2024-09-06T14:04:35.228023Z",
     "shell.execute_reply.started": "2024-09-06T14:04:35.221364Z"
    }
   },
   "outputs": [],
   "source": [
    "class Convert:\n",
    "\n",
    "    def __init__(self, lst: list, file_path='./item_list.pkl'):\n",
    "        self.lst = lst\n",
    "        self.file_path = file_path\n",
    "\n",
    "        # 对 lst 进行编码\n",
    "        self.item_list = None\n",
    "        self.item_dict = None\n",
    "        self.parse()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_dict(item_list):\n",
    "        item_dict = dict()\n",
    "        for i, item in enumerate(item_list):\n",
    "            item_dict[item] = i\n",
    "        return item_dict\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"对列表元素编码\"\"\"\n",
    "\n",
    "        # 统计字符串频率\n",
    "        frequency = collections.Counter(self.lst)\n",
    "\n",
    "        # 按字符串频率，倒序排列\n",
    "        sorted_items = sorted(frequency.items(),\n",
    "                              key=lambda e: e[1],\n",
    "                              reverse=True)\n",
    "\n",
    "        self.item_list = [e[0] for e in sorted_items]\n",
    "        self.item_dict = self.to_dict(self.item_list)\n",
    "\n",
    "    def reset(self):\n",
    "        self.item_list = self.read_item_list()\n",
    "        self.item_dict = self.to_dict(self.item_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.item_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.item_list[index]\n",
    "\n",
    "    def encoder(self, item):\n",
    "        return self.item_dict.get(item)\n",
    "\n",
    "    def save_item_list(self):\n",
    "        with open(self.file_path, 'wb') as f:\n",
    "            pickle.dump(self.item_list, f)\n",
    "\n",
    "    def read_item_list(self):\n",
    "        with open(self.file_path, 'rb') as f:\n",
    "            item_list = pickle.load(f)\n",
    "        return item_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f16532-2b08-4e07-9a04-8e2a6e7526fc",
   "metadata": {},
   "source": [
    "简单应用一下 `Convert`，首先将它实例化 `cv = Convert(items)`\n",
    "- `cv[i]`：获取编码为 `i` 的 item 的名称\n",
    "- `cv.encoder([ITEM_NAME])`：获取名称为 `[ITEM_NAME]` 的 item 的编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ba774d-d954-4995-bced-b5f755bbcf98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:35.233794Z",
     "iopub.status.busy": "2024-09-06T14:04:35.233517Z",
     "iopub.status.idle": "2024-09-06T14:04:35.895132Z",
     "shell.execute_reply": "2024-09-06T14:04:35.894345Z",
     "shell.execute_reply.started": "2024-09-06T14:04:35.233770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv.read_item_list() == cv.item_list: True\n",
      "cv[0]: whole milk\n",
      "cv.encoder(\"pot plants\"): 72\n",
      "len(cv): 167\n"
     ]
    }
   ],
   "source": [
    "# 获取 Spark DataFrame 中的 item Description 字段\n",
    "items = [row.itemDescription for row in spark_df.collect()]\n",
    "pkl_path = utils.gen_abspath(CSV_PATH, PLK_FILE)\n",
    "cv = Convert(items, file_path=pkl_path)\n",
    "\n",
    "# 将编码的映射逻辑存成 pkl 文件\n",
    "cv.save_item_list()\n",
    "\n",
    "# 读 pkl 文件，看保存的 item_list 是否与当前相同\n",
    "print(f'cv.read_item_list() == cv.item_list: {cv.read_item_list() == cv.item_list}')\n",
    "\n",
    "# 用 pkl 文件的 item_list 重置 cv\n",
    "cv = Convert([], file_path=pkl_path)\n",
    "cv.reset()\n",
    "\n",
    "# 获取编码为 2 的 item \n",
    "print(f'cv[0]: {cv[0]}')\n",
    "\n",
    "# 获取 item  为 pot plants 的编码\n",
    "print(f'cv.encoder(\"pot plants\"): {cv.encoder(\"pot plants\")}')\n",
    "\n",
    "# 计算无重复 item  的个数\n",
    "print(f'len(cv): {len(cv)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227c518-5d72-49d4-81b5-d4cdff484b12",
   "metadata": {},
   "source": [
    "将 `cv.encoder` 注册为 Spark UDF，然后对 Spark 的每一行使用该 UDF，将 item 的名称转换为编码。产出一个新列 `itemCode` 用来存放 item 的编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e298eda5-a51a-4c7e-9ff6-aeff0af97592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:35.896866Z",
     "iopub.status.busy": "2024-09-06T14:04:35.896468Z",
     "iopub.status.idle": "2024-09-06T14:04:37.714081Z",
     "shell.execute_reply": "2024-09-06T14:04:37.713242Z",
     "shell.execute_reply.started": "2024-09-06T14:04:35.896841Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+----------------+--------+\n",
      "|Member_number|      Date| itemDescription|itemCode|\n",
      "+-------------+----------+----------------+--------+\n",
      "|         1808|21-07-2015|  tropical fruit|       6|\n",
      "|         2552|05-01-2015|      whole milk|       0|\n",
      "|         2300|19-09-2015|       pip fruit|      11|\n",
      "|         1187|12-12-2015|other vegetables|       1|\n",
      "|         3037|01-02-2015|      whole milk|       0|\n",
      "|         4941|14-02-2015|      rolls/buns|       2|\n",
      "|         4501|08-05-2015|other vegetables|       1|\n",
      "|         3803|23-12-2015|      pot plants|      72|\n",
      "|         2762|20-03-2015|      whole milk|       0|\n",
      "|         4119|12-02-2015|  tropical fruit|       6|\n",
      "+-------------+----------+----------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 将函数注册为 Spark UDF，返回值类型设为 Integer\n",
    "encoder_udf = F.udf(cv.encoder, IntegerType())\n",
    "\n",
    "# 在 DataFrame 上应用此函数\n",
    "spark_df = spark_df.withColumn(\"itemCode\", encoder_udf(F.col(\"itemDescription\")))\n",
    "\n",
    "spark_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34ec502d-ba02-4819-a7d9-991ea0b96223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:37.716207Z",
     "iopub.status.busy": "2024-09-06T14:04:37.715804Z",
     "iopub.status.idle": "2024-09-06T14:04:39.300108Z",
     "shell.execute_reply": "2024-09-06T14:04:39.298997Z",
     "shell.execute_reply.started": "2024-09-06T14:04:37.716168Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|Member_number|           itemCodes|\n",
      "+-------------+--------------------+\n",
      "|         1000|[0, 48, 13, 67, 5...|\n",
      "|         1001|[0, 15, 2, 17, 24...|\n",
      "|         1002|[0, 27, 1, 6, 42,...|\n",
      "|         1003|[45, 121, 5, 2, 6...|\n",
      "|         1004|[0, 1, 31, 2, 89,...|\n",
      "|         1005|         [15, 2, 25]|\n",
      "|         1006|[0, 12, 31, 64, 2...|\n",
      "|         1008|[96, 34, 5, 20, 1...|\n",
      "|         1009|[60, 16, 6, 123, ...|\n",
      "|         1010|[2, 17, 125, 36, ...|\n",
      "+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 把具有相同 Member_number 的所有 itemCode 聚成一个无重复列表\n",
    "items_df = spark_df.groupBy(\"Member_number\").agg(F.collect_set(\"itemCode\").alias(\"itemCodes\"))\n",
    "\n",
    "# 显示结果\n",
    "items_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9cec4f-30ed-4cad-a3c1-f595fcd0e94b",
   "metadata": {},
   "source": [
    "## 2. 频繁项挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d0fb5a-bd4f-4e5b-b1b4-0f51ce061223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:39.301931Z",
     "iopub.status.busy": "2024-09-06T14:04:39.301653Z",
     "iopub.status.idle": "2024-09-06T14:04:39.306634Z",
     "shell.execute_reply": "2024-09-06T14:04:39.305548Z",
     "shell.execute_reply.started": "2024-09-06T14:04:39.301910Z"
    }
   },
   "outputs": [],
   "source": [
    "def freq2support(min_freq, seq_cnt):\n",
    "    \"\"\"由频数计算支持度\"\"\"\n",
    "    support = min_freq / seq_cnt\n",
    "    return support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528931ac-b332-4025-9863-3d76770861d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:39.308207Z",
     "iopub.status.busy": "2024-09-06T14:04:39.307801Z",
     "iopub.status.idle": "2024-09-06T14:04:41.206856Z",
     "shell.execute_reply": "2024-09-06T14:04:41.205932Z",
     "shell.execute_reply.started": "2024-09-06T14:04:39.308184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "序列的数量：3898\n",
      "无重复序列的数量：3873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "seq_cnt = items_df.count()\n",
    "distinct_seq_cnt = len(set(['_'.join(map(str, sorted(s))) for s in [row.itemCodes for row in items_df.collect()]]))\n",
    "\n",
    "print(f'序列的数量：{seq_cnt}')\n",
    "print(f'无重复序列的数量：{distinct_seq_cnt}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efd125-4155-40d3-9912-fe4f122680c9",
   "metadata": {},
   "source": [
    "### 2.1 频繁项集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fad0212-ca99-4290-96b6-2c8a8d30790d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:41.208670Z",
     "iopub.status.busy": "2024-09-06T14:04:41.208216Z",
     "iopub.status.idle": "2024-09-06T14:04:43.995934Z",
     "shell.execute_reply": "2024-09-06T14:04:43.995004Z",
     "shell.execute_reply.started": "2024-09-06T14:04:41.208624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_freq: 50\n",
      "min_support: 0.0128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|     items|freq|\n",
      "+----------+----+\n",
      "|      [92]|  71|\n",
      "|     [102]|  60|\n",
      "|      [83]|  85|\n",
      "|      [24]| 471|\n",
      "|   [24, 8]| 125|\n",
      "|[24, 8, 2]|  59|\n",
      "|[24, 8, 4]|  58|\n",
      "|[24, 8, 1]|  58|\n",
      "|[24, 8, 3]|  52|\n",
      "|[24, 8, 0]|  74|\n",
      "+----------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "min_freq = 50\n",
    "min_support = freq2support(min_freq=min_freq, seq_cnt=seq_cnt)\n",
    "print(f'min_freq: {min_freq}')\n",
    "print(f'min_support: {min_support:.4f}')\n",
    "\n",
    "fpGrowth = FPGrowth(itemsCol=\"itemCodes\", minSupport=min_support, minConfidence=0.5)\n",
    "model = fpGrowth.fit(items_df)\n",
    "\n",
    "# Display frequent item sets.\n",
    "model.freqItemsets.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276daa6b-ba1d-4f26-ab77-514cdbe2c053",
   "metadata": {},
   "source": [
    "### 2.2 关联规则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7599f77d-f9c9-4772-a491-69699d04b58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-06T14:04:43.997667Z",
     "iopub.status.busy": "2024-09-06T14:04:43.997156Z",
     "iopub.status.idle": "2024-09-06T14:04:45.514935Z",
     "shell.execute_reply": "2024-09-06T14:04:45.514046Z",
     "shell.execute_reply.started": "2024-09-06T14:04:43.997642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+------------------+--------------------+\n",
      "|antecedent|consequent|        confidence|              lift|             support|\n",
      "+----------+----------+------------------+------------------+--------------------+\n",
      "|   [29, 6]|       [0]|0.5842696629213483|1.2751865319526403|0.013340174448435094|\n",
      "|  [14, 13]|       [0]|0.5689655172413793|1.2417847627138279| 0.01693175987685993|\n",
      "|   [22, 3]|       [0]|0.5232558139534884|1.1420219276543662|0.023088763468445357|\n",
      "| [5, 4, 1]|       [0]|0.5909090909090909|1.2896772879975569|0.020010261672652643|\n",
      "|  [16, 14]|       [0]|0.5631067961165048|1.2289979234390458|0.014879425346331451|\n",
      "|      [18]|       [0]|0.5132075471698113|1.1200912759618837| 0.06977937403796819|\n",
      "|  [24, 12]|       [0]|0.6086956521739131|  1.32849700569648|0.014366341713699333|\n",
      "|   [12, 3]|       [0]|0.5674603174603174|1.2384996178389234| 0.03668547973319651|\n",
      "|  [20, 14]|       [0]|0.6391752577319587|1.3950196834485862| 0.01590559261159569|\n",
      "|   [17, 5]|       [0]|0.5197368421052632|1.1343416632286203|0.020266803488968702|\n",
      "+----------+----------+------------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------------+--------------------+----------+\n",
      "|Member_number|           itemCodes|prediction|\n",
      "+-------------+--------------------+----------+\n",
      "|         1000|[0, 48, 13, 67, 5...|    [2, 1]|\n",
      "|         1001|[0, 15, 2, 17, 24...|       [1]|\n",
      "|         1002|[0, 27, 1, 6, 42,...|       [2]|\n",
      "|         1003|[45, 121, 5, 2, 6...|    [0, 1]|\n",
      "|         1004|[0, 1, 31, 2, 89,...|        []|\n",
      "|         1005|         [15, 2, 25]|       [0]|\n",
      "|         1006|[0, 12, 31, 64, 2...|       [1]|\n",
      "|         1008|[96, 34, 5, 20, 1...|    [0, 2]|\n",
      "|         1009|[60, 16, 6, 123, ...|       [0]|\n",
      "|         1010|[2, 17, 125, 36, ...|    [1, 0]|\n",
      "+-------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display generated association rules.\n",
    "model.associationRules.show(10)\n",
    "\n",
    "# transform examines the input item s against all the association rules and summarize the\n",
    "# consequents as prediction\n",
    "model.transform(items_df).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d357fa-017d-40af-a637-5a28bd29ac7e",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;border:#254E58 solid;padding: 15px;background-color:white;font-size:110%;text-align:left\">\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>📝 关联规则挖掘：</font></h3> \n",
    "\n",
    "关联规则挖掘是一种运用模式识别来识别和量化不同但相关 item 之间关系的处理过程。\n",
    "\n",
    "一个简单的关联规则用例：\n",
    "\n",
    "鸡蛋和面包经常一起购买。有了这个发现，你可以通过以下方式增加销售额：\n",
    "\n",
    "- 将鸡蛋和面包放在一起，这样当顾客购买其中一种产品时，他们不需要走到别处去购买另一种产品。\n",
    "- 向购买鸡蛋或面包的顾客做广告，以增加他们购买（配对的）另一种产品的倾向。\n",
    "- 如果顾客一次性购买鸡蛋和面包，就为两者提供折扣。\n",
    "\n",
    "**关联规则：**\n",
    "    “如果购买了鸡蛋，那么购买面包的可能性是____”\n",
    "\n",
    "也可以表示为：\n",
    "- {鸡蛋} -> {面包}\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>优点：</font></h3> \n",
    "\n",
    "- 相对快速的方法\n",
    "- 在小量数据上表现良好\n",
    "- 几乎不需要（如果有的话）特征工程\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>衡量关联性的三种方式：</font></h3> \n",
    "\n",
    "1. 支持度\n",
    "2. 置信度\n",
    "3. 提升度\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>举例说明：</font></h3>  \n",
    "场景：超市共有5000笔交易\n",
    "\n",
    "- A = 面包购买次数 = 500笔交易\n",
    "- C = 鸡蛋购买次数 = 350笔交易\n",
    "- (A->C) = 同时购买面包和鸡蛋的次数 = 150笔交易\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>支持度：</font></h3>\n",
    "\n",
    "- 支持度是数据集中某个 item 相对频率。它基本上表达了该 item 的受欢迎程度，由其在总销售 item 中的比例来表示。\n",
    "-  item 的支持度 support 可以这样计算\n",
    "``` support(A->C) = Support (A ∪ C)```\n",
    "\n",
    " 示例：\n",
    "  - 面包的支持度 = （包含面包的交易次数） / （总交易次数）\n",
    "  - 面包的支持度 = 500 / 5000 = 0.1\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>置信度：</font></h3> \n",
    "\n",
    "- 置信度是在数据中给定也包含前件（\"if\" 项）的情况下，看到后件（\"then\" 项）的概率\n",
    "- 换句话说，置信度告诉你给定另一个 item 已购买的情况下，一个 item 被购买的可能性是多少\n",
    "- 置信度决定了数据集中有多少 if-then 语句被证实为真\n",
    "\n",
    "``` Confidence(A -> C) = (Support(A -> C)) / (Support(A))```\n",
    "\n",
    "    其中\n",
    "    A - 前件\n",
    "    C - 后件\n",
    "\n",
    "- 使用同样的例子，如果购买了面包，购买鸡蛋的可能性是：\n",
    "- Confidence(面包 -> 鸡蛋) = (150/5000) / (500/5000) = 0.3 = 30%\n",
    "- 因此，如果购买了面包，有 30% 的可能性会购买鸡蛋。\n",
    "\n",
    "<h3 align=\"left\"><font color=#254E58>提升度：</font></h3>\n",
    "\n",
    "- 提升度是一个衡量前件和后件一起出现频率与它们独立出现频率的比率的指标。\n",
    "\n",
    "-  ``` Lift(A -> C) = (Confidence(A -> C)) / (Support(C))```\n",
    "\n",
    "- 提升度 > 1: A 与 C 高度相关。如果购买了 A，那么很可能也会购买 C。\n",
    "- 提升度 < 1: 如果购买了 A，那么购买 C 的可能性不大。\n",
    "- 提升度 = 1: 表示 item A 和 C 之间没有关联。\n",
    "- 提升度(面包 -> 鸡蛋) = 0.3 / (350 / 5000) = 4.28\n",
    "- 以 4.28 的提升度，你的规则将是“如果顾客购买面包，那么他们很可能会购买鸡蛋”。\n",
    "\n",
    "Apriori算法是用来在结构化数据上实施关联规则挖掘的算法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fc1a21-4b3b-4ceb-ad0f-434be9e92731",
   "metadata": {},
   "source": [
    "参考：\n",
    "\n",
    "- [Frequent Pattern Mining](https://spark.apache.org/docs/latest/ml-frequent-pattern-mining.html)\n",
    "- [Market Basket Analysis with Apriori Algorithm](https://www.kaggle.com/code/prasad22/market-basket-analysis-with-apriori-algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41210c4-841b-4c2b-944d-fc46442cb971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
